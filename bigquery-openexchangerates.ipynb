{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "APP_ID = \"secret\"\n",
    "BASE_CURRENCY = \"EUR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery, storage\n",
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "def csv_to_bq(project_id, dataset_id, destination_table_id, bucket_name, source_file_name, table_schema):\n",
    "    destination_blob_name = dataset_id + '/' + destination_table_id + '.csv'\n",
    "\n",
    "    \"\"\"\n",
    "    Uploads a file to the bucket.\n",
    "    https://cloud.google.com/storage/docs/uploading-objects\n",
    "    \"\"\"\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print('Uploaded file {} to {}.'.format(source_file_name, destination_blob_name))\n",
    "\n",
    "    \"\"\"\n",
    "    Load CSV from GCS to BQ\n",
    "    https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv\n",
    "    \"\"\"\n",
    "    dataset_ref = bq_client.dataset(dataset_id)\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.schema = table_schema\n",
    "    job_config.skip_leading_rows = 1\n",
    "    job_config.max_bad_records = 100\n",
    "    job_config.field_delimiter = \",\"\n",
    "    job_config.source_format = bigquery.SourceFormat.CSV # The source format defaults to CSV, so this line is optional.\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE # https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv#loading_csv_data_with_schema_auto-detection\n",
    "    job_config.allow_quoted_newlines = True\n",
    "\n",
    "    uri = 'gs://' + bucket_name + '/' + destination_blob_name\n",
    "\n",
    "    load_job = bq_client.load_table_from_uri(\n",
    "        uri,\n",
    "        dataset_ref.table(destination_table_id),\n",
    "        job_config=job_config)  # API request\n",
    "    print('Starting job {} from {}'.format(load_job.job_id, uri))\n",
    "\n",
    "    load_job.result()  # Waits for table load to complete.\n",
    "    print('Job finished.')\n",
    "\n",
    "    destination_table = bq_client.get_table(dataset_ref.table(destination_table_id))\n",
    "    print('Resulted table has {} rows.'.format(destination_table.num_rows))\n",
    "    \n",
    "    return load_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = requests.get(\"https://openexchangerates.org/api/latest.json\", params={'app_id': APP_ID, 'base': BASE_CURRENCY})\n",
    "\n",
    "r = requests.get(\"https://openexchangerates.org/api/latest.json\", params={'app_id': APP_ID}, verify=False)\n",
    "data = r.json()\n",
    "request_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [[data['base'], key, data['rates'][key]] for key in data['rates']]\n",
    "\n",
    "df = pd.DataFrame(data_list, columns=[\"from\", \"to\", \"rate\"])\n",
    "df[\"date\"] = request_time.strftime(\"%Y%m%d\")\n",
    "df[\"datetime\"] = request_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "df[\"timestamp\"] = int(request_time.timestamp())\n",
    "\n",
    "tablename = \"openexchangerates_\" + str(int(request_time.timestamp()))\n",
    "filename = \"./\" + tablename + \".csv\"\n",
    "\n",
    "df.to_csv(filename, encoding='utf-8', index=False)\n",
    "\n",
    "project_id = 'project_id'\n",
    "dataset_id = 'dataset_id'\n",
    "destination_table_id = tablename\n",
    "bucket_name = 'bucket_name'\n",
    "source_file_name = filename\n",
    "table_schema = [\n",
    "    bigquery.SchemaField('from', 'STRING'),\n",
    "    bigquery.SchemaField('to', 'STRING'),\n",
    "    bigquery.SchemaField('rate', 'FLOAT'),\n",
    "    bigquery.SchemaField('date', 'STRING'),\n",
    "    bigquery.SchemaField('datetime', 'STRING'),\n",
    "    bigquery.SchemaField('timestamp', 'TIMESTAMP'),\n",
    "]\n",
    "\n",
    "csv_to_bq(project_id, dataset_id, destination_table_id, bucket_name, source_file_name, table_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
